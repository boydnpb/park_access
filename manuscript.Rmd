---
title: "Manuscript"
author: "Nico Boyd, Greg Macfarlane, Kari Watkins, Dave Ederer"
date: "6/16/2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup}
library(geojsonio)
library(leaflet)
library(tidyverse)
library(spdep)
library(maptools)
library(rgdal)
library(rgeos)
library(texreg)
library(leaflet)


# source functions
source("R/logsums.R")

# variables
cities <- c("denver", "boston", "nyc")
```


# Abstract

## Introduction
This research will identify the correlation between size and access to urban parks, and physical activity, obesity and mental health at the neighborhood level. Proximity to parks is associated with increased physical activity and reduced obesity, but little research has been conducted on the relationship between accessibility to parks and health outcomes. 

## Methods
Using data for three urban areas, we created a new measure for access to parks called park choice accessibility. Park choice accessibility uses a gravity model to interact distance to parks and quality of those parks as defined by size and amenities. A small park very close to a neighborhood can have a major impact, but a larger park at a similar distance may have an even larger impact. Similarly, a large park can be further away and still have an impact on health outcomes. Using spatial regression analysis, we are assessing whether park choice accessibility is associated with increased physical activity or decreased prevalence of obesity at the neighborhood level. The analysis controls for socioeconomic covariates such as age, marital status, income, and educational attainment. 

## Results
Our anticipated results will assess the difference in physical activity and obesity at the neighborhood level when comparing proximity to parks and access to parks of various sizes and qualities as defined by park choice accessibility. We hope to make progress in achieving the Healthy People 2020 goals on physical activity, reduced sedentary behavior, and building healthy communities.


# Background/Literature Review




# Methods
```{r load_data}
denver_tracts <- geojson_read("data/denver_tracts.geojson", what = "sp")
denver_tracts$GEOID10 <- denver_tracts$GEOID_TRAC
denver_tracts$Phys_Act <- denver_tracts$PhysAct
denver_tracts$CollegeDeg <- denver_tracts$CollegePercent
denver_parks <- geojson_read ("data/denver_parks.geojson", what = "sp")


boston_tracts <- geojson_read("data/boston_tracts.geojson", what = "sp")
boston_parks <- geojson_read("data/boston_parks.geojson", what = "sp")
boston_parks$Park_Acres <- boston_parks$Acreage

nyc_tracts <- geojson_read("data/nyc_tracts.geojson", what = "sp")
nyc_tracts$GEOID10 <- nyc_tracts$GEOID
nyc_tracts$SinglePercent <- nyc_tracts$Single_Percent
nyc_parks <- geojson_read("data/nyc_parks.geojson", what = "sp")


tract_shapes <- list(denver_tracts, boston_tracts, nyc_tracts)
park_shapes <- list(denver_parks, boston_parks, nyc_parks)
```



# Results

## Denver

Plot Denver geospatial data (tracts and parks):
```{r denver_data}

#denver_tracts2 <- readOGR(dsn = "data/Denver_Data.gdb", layer = "Denver_Final") 
plot(denver_tracts)

#denver_parks2 <- readOGR(dsn = "data/Denver_Data.gdb", layer = "Denver_All_Parks") 
plot(denver_parks)
```

Transform the attribute table into a tibble and select the relevant variables:
```{r transformdata}
#TODO: make sure all cities have the same data in the same names. It will save 
# us LOTS of time
# denver only, because the other cities have different variables
regression_data <-
  lapply(seq_along(1:1), function(i) {
    tbl_df(tract_shapes[[i]]@data) %>%
      mutate(
        Park_Percent = ifelse(is.na(Park_Percent), 0, Park_Percent),
        city = cities[i]
      )
  })
```

DISCUSSION OF LOGSUM CALCULATION

Calculate the logsum given the tracts and parks dataset:
```{r accessibility}
regression_data[[1]]["park_ls"] <- calculate_park_logsums(
  denver_tracts, denver_parks, betas = c(.00001, -5))
regression_data[[2]]["park_ls"] <- calculate_park_logsums(
  boston_tracts, boston_parks, betas = c(.00001, -30))
regression_data[[1]]["park_ls"] <- calculate_park_logsums(
  nyc_tracts, nyc_parks, betas = c(.00001, -5))
```

Create regression equations for use in spatial econometric models:
```{r regression_eq}
base_formula <- formula(
  ~ Income1 + Income2 + Income3 + Income4 + Income5 + Income6 + Income7 + 
    Income8 + Income9 + Income10 + log(Pop_Density) + FulltimeWork + 
    CollegePercent + SinglePercent + Pct0to17 + Pct18to29 + Pct30to64 + 
    Pct65plus + PctWhite + PctBlack + PctNative + PctAsian + PctPacific + 
    PctOther + PctHispanic)

parks_formula <- update(base_formula, . ~ . + park_ls)
```

Locate the centroid of all parks and all census tracts and create a distance matrix:
```{r distancematrix}
# why are we computing the distance matrices if we are using contiguity-based
# neighbors?
tract_centroids <- lapply(seq_along(1:length(cities)), function(i){
  gCentroid(tract_shapes[[i]], byid = TRUE)
})

park_centroids <- lapply(seq_along(1:length(cities)), function(i){
  gCentroid(park_shapes[[i]], byid = TRUE)
})

distance_matrices <- lapply(seq_along(1:length(cities)), function(i){
  gDistance(tract_centroids[[i]], park_centroids[[i]], byid = TRUE)
})

names(distance_matrices) <- names(tract_centroids) <- names(park_centroids) <- cities
```


```{r listw}
list_ws <- lapply(seq_along(1:length(cities)), function(i){
  nb <- poly2nb(tract_shapes[[i]], queen = FALSE)
  nb2listw(neighbours = nb, zero.policy = TRUE)
})
names(list_ws) <- cities
```

Estimate spatial econometric models for the `OBESITY` variable. The first model
of each different type does not include `park_ls`:

```{r linear_models}
# this lets us run all of the linear models (for all the cities) in like ten 
# lines of code
dependent_variables <- c("OBESITY", "PhysAct", "MENTAL")

base_lm <- lapply(seq_along(1:length(dependent_variables)), function(i){
  
  this_formula <- substitute(update(base_formula, x ~ .), 
                             list(x = as.name(dependent_variables[i]) ))
  
  bind_rows(regression_data) %>%
    split(.$city) %>%
    map(~lm(this_formula, data = .))
})

parks_lm <- lapply(seq_along(1:length(dependent_variables)), function(i){
  
  this_formula <- substitute(update(parks_formula, x ~ .), 
                             list(x = as.name(dependent_variables[i]) ))
  
  bind_rows(regression_data) %>%
    split(.$city) %>%
    map(~lm(this_formula, data = .))
})


names(parks_lm) <- names(base_lm) <- dependent_variables
# get a model with summary(base_lm$OBESITY$denver), for instance.
```

```{r sem}
base_sem <- lapply(seq_along(1:length(dependent_variables)), function(dv){
  this_formula <- substitute(update(base_formula, x ~ .), 
                             list(x = as.name(dependent_variables[dv]) ))
  
  # TODO update when more cities are available
  models <- lapply(seq_along(1:1), function(city){
    errorsarlm(this_formula, data = regression_data[[city]],
               listw = list_ws[[city]], zero.policy = TRUE)
  })
  
  names(models) <- cities[1]
  return(models)
})

park_sem <- lapply(seq_along(1:length(dependent_variables)), function(dv){
  this_formula <- substitute(update(parks_formula, x ~ .), 
                             list(x = as.name(dependent_variables[dv]) ))
  
  # TODO update when more cities are available
  models <- lapply(seq_along(1:1), function(city){
    errorsarlm(this_formula, data = regression_data[[city]],
               listw = list_ws[[city]], zero.policy = TRUE)
  })
  
  names(models) <- cities[1]
  return(models)
})

names(park_sem) <- names(base_sem) <- dependent_variables
```

```{r sdm}
base_sdm <- lapply(seq_along(1:length(dependent_variables)), function(dv){
  this_formula <- substitute(update(base_formula, x ~ .), 
                             list(x = as.name(dependent_variables[dv]) ))
  
  # TODO update when more cities are available
  models <- lapply(seq_along(1:1), function(city){
    lagsarlm(this_formula, data = regression_data[[city]],
             listw = list_ws[[city]], zero.policy = TRUE, type = "mixed")
  })
  
  names(models) <- cities[1]
  return(models)
})

park_sdm <- lapply(seq_along(1:length(dependent_variables)), function(dv){
  this_formula <- substitute(update(parks_formula, x ~ .), 
                             list(x = as.name(dependent_variables[dv]) ))
  
  # TODO update when more cities are available
  models <- lapply(seq_along(1:1), function(city){
    lagsarlm(this_formula, data = regression_data[[city]],
             listw = list_ws[[city]], zero.policy = TRUE, type = "mixed")
  })
  
  names(models) <- cities[1]
  return(models)
})

names(park_sdm) <- names(base_sdm) <- dependent_variables
```


Calculate the impacts of the spatial durbin models:
```{r SDM_impacts}
tr_mc <- lapply(list_ws, function(x){
  trW(as(x, "CsparseMatrix"), type="MC")
})


mc_impacts <- lapply(base_sdm, function(dv){
  # TODO
  impacts <- lapply(seq_along(1:1), function(i) {
    impacts(dv[[i]], tr = tr_mc[[i]])
  })
  
  names(impacts) <- cities[i]
  
  return(impacts)
})
names(mc_impacts) <- dependent_variables
```

Compare the models with `htmlreg()`. First the obesity models:
```{r denver_obesity_summary, results="asis", eval=FALSE}
denver_obesity_models <- list(
  base_sem$OBESITY$denver, park_sem$OBESITY$denver,
  base_sdm$OBESITY$denver, park_sdm$OBESITY$denver
)

names(denver_obesity_models) <- paste(rep(c("SEM", "SDM"), each = 2), 
                                      rep(c("Base", "Parks")))

htmlreg(denver_obesity_models, caption = "Denver: Models of Obesity Prevalence")
```

Next, the physical activity models:
```{r denver_physact_summary, results="asis", eval=FALSE}
denver_physact_models <- list(
  base_sem$PhysAct$denver, park_sem$PhysAct$denver,
  base_sdm$PhysAct$denver, park_sdm$PhysAct$denver
)
names(denver_physact_models) <- paste(rep(c("SEM", "SDM"), each = 2),
                                      rep(c("Base", "Parks")))
htmlreg(denver_physact_models, caption = "Denver: Models of Physical Activity Participation")
```

And third, the mental health models:




# Discussion





# Conclusion
