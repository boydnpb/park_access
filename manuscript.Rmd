---
title: "Manuscript"
author: "Nico Boyd, Greg Macfarlane, Kari Watkins, Dave Ederer"
date: "6/16/2017"
output:
  html_document: default
  pdf_document: default
---

```{r setup, cache = FALSE, warning = FALSE, message = FALSE}
library(geojsonio)
library(leaflet)
library(tidyverse)
library(spdep)
library(maptools)
library(rgdal)
library(rgeos)
library(texreg)
library(leaflet)

knitr::opts_chunk$set(cache = TRUE)

# source functions
source("R/logsums.R")
source("R/impact_summary.R")

# variables
cities <- c("boston", "denver", "nyc")
```


# Abstract

## Introduction
This research will identify the correlation between size and access to urban parks, and physical activity, obesity and mental health at the neighborhood level. Proximity to parks is associated with increased physical activity and reduced obesity, but little research has been conducted on the relationship between accessibility to parks and health outcomes. 

## Methods
Using data for three urban areas, we created a new measure for access to parks called park choice accessibility. Park choice accessibility uses a gravity model to interact distance to parks and quality of those parks as defined by size and amenities. A small park very close to a neighborhood can have a major impact, but a larger park at a similar distance may have an even larger impact. Similarly, a large park can be further away and still have an impact on health outcomes. Using spatial regression analysis, we are assessing whether park choice accessibility is associated with increased physical activity or decreased prevalence of obesity at the neighborhood level. The analysis controls for socioeconomic covariates such as age, marital status, income, and educational attainment. 

## Results
Our anticipated results will assess the difference in physical activity and obesity at the neighborhood level when comparing proximity to parks and access to parks of various sizes and qualities as defined by park choice accessibility. We hope to make progress in achieving the Healthy People 2020 goals on physical activity, reduced sedentary behavior, and building healthy communities.


# Background/Literature Review




# Methods
```{r load_data}
# I've standardized the variable names based on the Boston dataset, so let's use those variable names moving forward. I also removed the Northeasternmost census tract from the Denver dataset as you suggested.

## I removed the really large Northeasternmost census tracts from Boston as well as a number of private parks. I also removed professional sports stadiums from the NYC parks dataset.

denver_tracts <- geojson_read("data/denver_tracts.geojson", what = "sp")
denver_tracts$GEOID10 <- denver_tracts$GEOID_TRAC
denver_tracts$Phys_Act <- denver_tracts$PhysAct
denver_tracts$CollegeDeg <- denver_tracts$CollegePercent
denver_parks <- geojson_read ("data/denver_parks.geojson", what = "sp")


boston_tracts <- geojson_read("data/boston_tracts.geojson", what = "sp")
boston_parks <- geojson_read("data/boston_parks_final.geojson", what = "sp")
boston_parks$Park_Acres <- boston_parks$Acreage

nyc_tracts <- geojson_read("data/nyc_tracts.geojson", what = "sp")
nyc_tracts$GEOID10 <- nyc_tracts$GEOID
nyc_tracts$SinglePercent <- nyc_tracts$Single_Percent
nyc_parks <- geojson_read("data/nyc_parks_final.geojson", what = "sp")


tract_shapes <- list (boston_tracts, denver_tracts, nyc_tracts)
park_shapes <- list(boston_parks, denver_parks, nyc_parks)
```


Consider that an individual is choosing a park for a recreation activity.
According to basic choice theory (Mcfadden 1974), the probability of choosing
park $i$ from the set of all regional parks $P$ is:

$$ P(i | V_i) = \frac{\exp(V_i)}{\sum_{j \in P}\exp(V_j)}$$
where parks are differentiated from each other by their relative measurable
utilitie $V$. In principle, $V$ may include any measurable attributes of either
the choice maker or the park. In this study we use an elementary linear formulation of

$$V_i = \beta_a acreage + \beta_d distance$$
incorporating the size of the park in acres and the distance of the park from
each census tract in miles. The coefficients $\beta$ are typically estimated from 
surveys, though in the absence of a survey we apply a maximum likelihood
technique described below.

A key theoretical understanding of random utility choice models is that the
consumer surplus of the choice set can be otained as the log-sum of the
denominator of the choice probability equation. In plainer terms, the *total value*
of an individual's park accessibility is defined to be:

$$\ln\left({\sum_{j \in P}\exp(V_j)}\right)$$

There are several advantages to a log-sum defined metric relative to
buffer-based accessibility metrics more commonly found in the literature. First,
all individuals are defined as having some access to all parks, rather than an
arbitrary limit of 1/2 mile or so. This allows for the fact that some people are
more or less sensitive to distances, and that distance is a continuous, and not
a binary, phenomenon. Second, the random utility formulation allows the
researcher to include any attribute of the park; in this case, we consider the
size of the park as an element of accessibility. This suggests that not all
parks are equal, and that a large park such as New York City's Central Park may
provide health and activity benefits over a much larger area than a smaller
community square.

McFadden, D. (1974). The measurement of urban travel demand. Journal of public economics, 3(4), 303-328.

In the absence of a park choice survey, we estimated likely values of the $\beta$ 
coefficients by iteratively searching for the values which produced the highest
model likelihood in *which model did we use to estimate likelihood?*. The search
was constrained by two assertions. First, we required that the coefficient on
size be positive and that on distance negative; all else equal, people will
prefer to use larger parks that are nearer to their residence. Second, we visually
inspected the resulting accessibility scores to ensure that the scores produced a 
reasonably varied pattern of access throughout the metropolitan region.


```{r transformdata}
#TODO: make sure all cities have the same data in the same names. It will save 
# us LOTS of time
# denver only, because the other cities have different variables
regression_data <-
  lapply(seq_along(1:length(cities)), function(i) {
    tbl_df(tract_shapes[[i]]@data) %>%
      mutate(
        Park_Percent = ifelse(is.na(Park_Percent), 0, Park_Percent),
        city = cities[i]
      )
  })
```


```{r city_plots, eval = FALSE}
boston_plots <- spTransform(boston_tracts, CRSobj = CRS("+init=epsg:4326"))
denver_plots <- spTransform(denver_tracts, CRSobj = CRS("+init=epsg:4326"))
nyc_plots <- spTransform(nyc_tracts, CRSobj = CRS("+init=epsg:4326"))
library(leaflet)
leaflet() %>%
  addTiles() %>%
  #addPolygons(data = nyc_plots)
  #addPolygons(data = denver_plots)
  addPolygons(data = boston_plots)
```


```{r betas}
betas <- list(
  boston = c(0.00001, -30), 
  denver = c(0.00001, -15), 
  nyc = c(0.0001, -5)
)
```


Calculate the logsum given the tracts and parks dataset:
```{r accessibility}
for(i in 1:length(cities)){
  regression_data[[i]]["park_ls"] <- calculate_park_logsums(
    tract_shapes[[i]], park_shapes[[i]], betas = betas[[i]])
}
```


# Results
Create regression equations for use in spatial econometric models:
We looked at income and it doesn't matter.
```{r regression_eq}
base_formula <- formula(
  ~ log(Pop_Density) + FulltimeWork + 
    CollegeDeg + SinglePercent + Pct0to17 + Pct18to29 + Pct30to64 + 
    Pct65plus + PctWhite + PctBlack + PctNative + PctAsian + PctPacific + 
    PctOther + PctHispanic)

parks_formula <- update(base_formula, . ~ . + park_ls)
```

Locate the centroid of all parks and all census tracts and create a distance matrix:
```{r distancematrix, eval = FALSE}
# why are we computing the distance matrices if we are using contiguity-based
# neighbors?
tract_centroids <- lapply(seq_along(1:length(cities)), function(i){
  gCentroid(tract_shapes[[i]], byid = TRUE)
})

park_centroids <- lapply(seq_along(1:length(cities)), function(i){
  gCentroid(park_shapes[[i]], byid = TRUE)
})

distance_matrices <- lapply(seq_along(1:length(cities)), function(i){
  gDistance(tract_centroids[[i]], park_centroids[[i]], byid = TRUE)
})

names(distance_matrices) <- names(tract_centroids) <- names(park_centroids) <- cities
```


```{r listw}
list_ws <- lapply(seq_along(1:length(cities)), function(i){
  nb <- poly2nb(tract_shapes[[i]], queen = FALSE)
  nb2listw(neighbours = nb, zero.policy = TRUE)
})
names(list_ws) <- cities
```

Estimate spatial econometric models for the `OBESITY` variable. The first model
of each different type does not include `park_ls`:

```{r linear_models}
# this lets us run all of the linear models (for all the cities) in like ten 
# lines of code
dependent_variables <- c("OBESITY", "Phys_Act", "MENTAL")

base_lm <- lapply(seq_along(1:length(dependent_variables)), function(i){
  
  this_formula <- substitute(update(base_formula, x ~ .), 
                             list(x = as.name(dependent_variables[i]) ))
  
  bind_rows(regression_data) %>%
    split(.$city) %>%
    map(~lm(this_formula, data = .))
})

parks_lm <- lapply(seq_along(1:length(dependent_variables)), function(i){
  
  this_formula <- substitute(update(parks_formula, x ~ .), 
                             list(x = as.name(dependent_variables[i]) ))
  
  bind_rows(regression_data) %>%
    split(.$city) %>%
    map(~lm(this_formula, data = .))
})


names(parks_lm) <- names(base_lm) <- dependent_variables
# get a model with summary(base_lm$OBESITY$denver), for instance.
```

A likelihood ratio test of the SDM and SEM revealed that the SDM is more likely.

```{r sem, eval = FALSE}
base_sem <- lapply(seq_along(1:length(dependent_variables)), function(dv){
  this_formula <- substitute(update(base_formula, x ~ .), 
                             list(x = as.name(dependent_variables[dv]) ))
  
  models <- lapply(seq_along(1:length(cities)), function(city){
    errorsarlm(this_formula, data = regression_data[[city]],
               listw = list_ws[[city]], zero.policy = TRUE)
  })
  
  names(models) <- cities
  return(models)
})

park_sem <- lapply(seq_along(1:length(dependent_variables)), function(dv){
  this_formula <- substitute(update(parks_formula, x ~ .), 
                             list(x = as.name(dependent_variables[dv]) ))
  
  models <- lapply(seq_along(1:length(cities)), function(city){
    errorsarlm(this_formula, data = regression_data[[city]],
               listw = list_ws[[city]], zero.policy = TRUE)
  })
  
  names(models) <- cities
  return(models)
})

names(park_sem) <- names(base_sem) <- dependent_variables
```

```{r sdm}
base_sdm <- lapply(seq_along(1:length(dependent_variables)), function(dv){
  this_formula <- substitute(update(base_formula, x ~ .), 
                             list(x = as.name(dependent_variables[dv]) ))
  
  models <- lapply(seq_along(1:length(cities)), function(city){
    lagsarlm(this_formula, data = regression_data[[city]],
             listw = list_ws[[city]], zero.policy = TRUE, type = "mixed",
             tol.solve = 1e-16)
  })
  
  names(models) <- cities
  return(models)
})

park_sdm <- lapply(seq_along(1:length(dependent_variables)), function(dv){
  this_formula <- substitute(update(parks_formula, x ~ .), 
                             list(x = as.name(dependent_variables[dv]) ))
  
  models <- lapply(seq_along(1:length(cities)), function(city){
    lagsarlm(this_formula, data = regression_data[[city]],
             listw = list_ws[[city]], zero.policy = TRUE, type = "mixed",
             tol.solve = 1e-16)
  })
  
  names(models) <- cities
  return(models)
})

names(park_sdm) <- names(base_sdm) <- dependent_variables
```


Calculate the impacts of the spatial durbin models:
```{r SDM_impacts}
tr_mc <- lapply(list_ws, function(x){
  trW(as(x, "CsparseMatrix"), type="MC")
})


mc_impacts <- lapply(park_sdm, function(dv){
  impacts <- lapply(seq_along(1:length(cities)), function(i) {
    impact_summary(summary(impacts(dv[[i]], tr = tr_mc[[i]], R = 500, empirical = TRUE)))
  })
  
  names(impacts) <- cities
  
  return(impacts)
})
names(mc_impacts) <- dependent_variables
```


Compare the models with `htmlreg()`. First the obesity models:
```{r denver_obesity_summary, results="asis", eval=FALSE}
denver_obesity_models <- list(
  base_sdm$OBESITY$denver, park_sdm$OBESITY$denver
  )

names(denver_obesity_models) <- paste(rep(c("SDM"), each = 2), 
                                      rep(c("Base", "Parks")))

screenreg(denver_obesity_models, caption = "Denver: Models of Obesity Prevalence")
```

Next, the physical activity models:
```{r denver_physact_summary, results="asis", eval=FALSE}
denver_physact_models <- list(
  base_sem$Phys_Act$denver, park_sem$Phys_Act$denver,
  base_sdm$Phys_Act$denver, park_sdm$Phys_Act$denver
)
names(denver_physact_models) <- paste(rep(c("SEM", "SDM"), each = 2),
                                      rep(c("Base", "Parks")))
screenreg(denver_physact_models, caption = "Denver: Models of Physical Activity Participation")
```

And third, the mental health models:




# Discussion





# Conclusion
